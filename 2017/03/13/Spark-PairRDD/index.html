<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    <title>Spark的键值对RDD | PLM&#39;s Notes | 好好学习，天天笔记</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Spark,PairRDD">
    <meta name="description" content="PairRDD及其创建 键值对RDD称为PairRDD，通常用来做聚合计算。Spark为Pair RDD提供了许多专有的操作。 1234# 创建pair rdd: map 或者 读取键值对格式自动转成pairrdd# 每行的第一个单词作为key，line作为valuepairs = lines.map(lambda">
<meta name="keywords" content="Spark,PairRDD">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark的键值对RDD">
<meta property="og:url" content="http://plmsmile.github.io/2017/03/13/Spark-PairRDD/index.html">
<meta property="og:site_name" content="PLM&#39;s Notes">
<meta property="og:description" content="PairRDD及其创建 键值对RDD称为PairRDD，通常用来做聚合计算。Spark为Pair RDD提供了许多专有的操作。 1234# 创建pair rdd: map 或者 读取键值对格式自动转成pairrdd# 每行的第一个单词作为key，line作为valuepairs = lines.map(lambda line: (line.split(&apos; &apos;)[0], line)) 转化操作">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2017-09-22T03:26:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark的键值对RDD">
<meta name="twitter:description" content="PairRDD及其创建 键值对RDD称为PairRDD，通常用来做聚合计算。Spark为Pair RDD提供了许多专有的操作。 1234# 创建pair rdd: map 或者 读取键值对格式自动转成pairrdd# 每行的第一个单词作为key，line作为valuepairs = lines.map(lambda line: (line.split(&apos; &apos;)[0], line)) 转化操作">
    
        <link rel="alternate" type="application/atom+xml" title="PLM&#39;s Notes" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.0">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="https://plmsmile.github.io/about" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">PLM</h5>
          <a href="mailto:plmsmile@126.com" title="plmsmile@126.com" class="mail">plmsmile@126.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                类别
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-user"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/plmsmile" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Spark的键值对RDD</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Spark的键值对RDD</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-03-13T11:37:06.000Z" itemprop="datePublished" class="page-time">
  2017-03-13
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/大数据/">大数据</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#pairrdd及其创建"><span class="post-toc-number">1.</span> <span class="post-toc-text">PairRDD及其创建</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#转化操作"><span class="post-toc-number">2.</span> <span class="post-toc-text">转化操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#单个pair-rdd转化"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">单个Pair RDD转化</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#两个pair-rdd转化"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">两个Pair RDD转化</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#行动操作"><span class="post-toc-number">3.</span> <span class="post-toc-text">行动操作</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#聚合操作"><span class="post-toc-number">4.</span> <span class="post-toc-text">聚合操作</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#数据分区"><span class="post-toc-number">5.</span> <span class="post-toc-text">数据分区</span></a></li></ol>
        </nav>
    </aside>
    
<article id="post-Spark-PairRDD"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Spark的键值对RDD</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-03-13 19:37:06" datetime="2017-03-13T11:37:06.000Z"  itemprop="datePublished">2017-03-13</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/大数据/">大数据</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h3 id="pairrdd及其创建">PairRDD及其创建</h3>
<p>键值对RDD称为PairRDD，通常用来做<code>聚合计算</code>。Spark为Pair RDD提供了许多专有的操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建pair rdd: map 或者 读取键值对格式自动转成pairrdd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每行的第一个单词作为key，line作为value</span></span><br><span class="line">pairs = lines.map(<span class="keyword">lambda</span> line: (line.split(<span class="string">' '</span>)[<span class="number">0</span>], line))</span><br></pre></td></tr></table></figure>
<h3 id="转化操作">转化操作</h3>
<p>Pair RDD 的转化操作分为单个和多个RDD的转化操作。</p>
<h4 id="单个pair-rdd转化">单个Pair RDD转化</h4>
<p><strong>reduceByKey(func)</strong></p>
<p><code>合并</code>含有相同键的值，也称作<code>聚合</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line">rdd = sc.parallelize([(<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">1</span>), (<span class="string">"a"</span>, <span class="number">1</span>)])</span><br><span class="line">sorted(rdd.reduceByKey(add).collect())</span><br><span class="line"><span class="comment"># [('a', 2), ('b', 1)]</span></span><br><span class="line"><span class="comment"># 这种写法也可以</span></span><br><span class="line">rdd.reduceByKey(<span class="keyword">lambda</span> x, y: x+y).collect()</span><br></pre></td></tr></table></figure>
<p><strong>groupByKey</strong></p>
<p>对具有相同键的值进行<code>分组</code>。会生成hash分区的RDD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">1</span>), (<span class="string">"a"</span>, <span class="number">1</span>)])</span><br><span class="line">sorted(rdd.groupByKey().mapValues(len).collect())</span><br><span class="line"><span class="comment"># [('a', 2), ('b', 1)]</span></span><br><span class="line">sorted(rdd.groupByKey().mapValues(list).collect())</span><br><span class="line">[(<span class="string">'a'</span>, [<span class="number">1</span>, <span class="number">1</span>]), (<span class="string">'b'</span>, [<span class="number">1</span>])]</span><br></pre></td></tr></table></figure>
<p>说明：如果对键进行分组以便对每个键进行聚合（如sum和average），则用<code>reduceByKey</code>和<code>aggregateByKey</code>性能更好</p>
<p><strong>combineByKey</strong></p>
<p>合并具有相同键的值，但是<code>返回不同类型</code> (K, V) - (K, C)。最常用的聚合操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">1</span>), (<span class="string">"a"</span>, <span class="number">1</span>)])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(a, b)</span>:</span> <span class="keyword">return</span> a + str(b)</span><br><span class="line">sorted(x.combineByKey(str, add, add).collect())</span><br><span class="line">[(<span class="string">'a'</span>, <span class="string">'11'</span>), (<span class="string">'b'</span>, <span class="string">'1'</span>)]</span><br></pre></td></tr></table></figure>
<p>下面是combineByKey的源码和参数说明</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](</span><br><span class="line">  	  createCombiner: <span class="type">V</span> =&gt; <span class="type">C</span>,		<span class="comment">// V =&gt; C的转变 / 初始值 / 创建one-element的list</span></span><br><span class="line">      mergeValue: (<span class="type">C</span>, <span class="type">V</span>) =&gt; <span class="type">C</span>,		<span class="comment">// 将原V累加到新的C</span></span><br><span class="line">      mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) =&gt; <span class="type">C</span>,	<span class="comment">// 两个C合并成一个</span></span><br><span class="line">      partitioner: <span class="type">Partitioner</span>,</span><br><span class="line">      mapSideCombine: <span class="type">Boolean</span> = <span class="literal">true</span>,</span><br><span class="line">      serializer: <span class="type">Serializer</span> = <span class="literal">null</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)] = &#123;</span><br><span class="line">    <span class="comment">//实现略</span></span><br><span class="line">  &#125;</span><br><span class="line"><span class="comment">// 求平均值</span></span><br><span class="line"><span class="keyword">val</span> scores = sc.parallelize(</span><br><span class="line">	<span class="type">List</span>((<span class="string">"chinese"</span>, <span class="number">88.0</span>) , (<span class="string">"chinese"</span>, <span class="number">90.5</span>) , (<span class="string">"math"</span>, <span class="number">60.0</span>), (<span class="string">"math"</span>, <span class="number">87.0</span>))</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> avg = scores.combineByKey(</span><br><span class="line">  (v) =&gt; (v, <span class="number">1</span>),</span><br><span class="line">  (acc: (<span class="type">Float</span>, <span class="type">Int</span>), <span class="type">V</span>) =&gt; (acc._1 + v, acc._2 + <span class="number">1</span>),</span><br><span class="line">  (acc1: (<span class="type">Float</span>, <span class="type">Int</span>), acc2: (<span class="type">Float</span>, <span class="type">Int</span>) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2))</span><br><span class="line">).map&#123;<span class="keyword">case</span> (key, value) =&gt; (key, value._1 / value._2.toFloat)&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求平均值</span></span><br><span class="line">nums = sc.parallelize([(<span class="string">'c'</span>, <span class="number">90</span>), (<span class="string">'m'</span>, <span class="number">95</span>), (<span class="string">'c'</span>, <span class="number">80</span>)])</span><br><span class="line">sum_count = nums.combineByKey(</span><br><span class="line">	<span class="keyword">lambda</span> x: (x, <span class="number">1</span>),</span><br><span class="line">    <span class="keyword">lambda</span> acc, x: (acc[<span class="number">0</span>] + x, acc[<span class="number">1</span>] + <span class="number">1</span>),</span><br><span class="line">    <span class="keyword">lambda</span> acc1, acc2: (acc1[<span class="number">0</span>] + acc2[<span class="number">0</span>], acc1[<span class="number">1</span>] + acc2[<span class="number">1</span>])</span><br><span class="line">)</span><br><span class="line"><span class="comment"># [('c', (170, 2)), ('m', (95, 1))]</span></span><br><span class="line">avg_map = sum_count.mapValues(<span class="keyword">lambda</span> (sum, count): sum/count).collectAsMap()</span><br><span class="line"><span class="comment"># &#123;'c': 85, 'm': 95&#125;</span></span><br><span class="line">avg_map = sum_count.map(<span class="keyword">lambda</span> key, s_c: (key, s_c[<span class="number">0</span>]/s_c[<span class="number">1</span>])).collectAsMap()</span><br></pre></td></tr></table></figure>
<p><strong>mapValues(f)</strong></p>
<p>对每个pair RDD中的每个Value应用一个func，不改变Key。其实也是<code>对value做map</code>操作。一般我们只想访问pair的值的时候，可以用<code>mapValues</code>。类似于map{case (x, y): (x, <em>func(y)</em>)}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">"a"</span>, [<span class="string">"apple"</span>, <span class="string">"banana"</span>, <span class="string">"lemon"</span>]), (<span class="string">"b"</span>, [<span class="string">"grapes"</span>])])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span> <span class="keyword">return</span> len(x)</span><br><span class="line">x.mapValues(f).collect()</span><br><span class="line">[(<span class="string">'a'</span>, <span class="number">3</span>), (<span class="string">'b'</span>, <span class="number">1</span>)]</span><br></pre></td></tr></table></figure>
<p><strong>mapPartitions(f)</strong></p>
<p>是<code>map</code>的一个变种，都需要传入一个函数f，去处理数据。不同点如下：</p>
<ul>
<li>map: f应用于每一个元素。</li>
<li>mapPartitions: f应用于每一个分区。分区的内容以Iterator[T]传入f，f的输出结果是Iterator[U]。最终RDD的由所有分区经过输入函数处理后的结果得到的。</li>
</ul>
<p>优点：我们可以为每一个分区做一些初始化操作，而不用为每一个元素做初始化。例如，初始化数据库，次数n。map时：n=元素数量，mapPartitions时：n=分区数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 每个元素加1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(iterator)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"called f"</span>)</span><br><span class="line">    <span class="keyword">return</span> map(<span class="keyword">lambda</span> x: x + <span class="number">1</span>, iterator)</span><br><span class="line">rdd = sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="number">2</span>)</span><br><span class="line">rdd.mapPartitions(f).collect()	<span class="comment"># 只调用2次f</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">called f</span></span><br><span class="line"><span class="string">called f</span></span><br><span class="line"><span class="string">[2, 3, 4, 5, 6]</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 分区求和</span></span><br><span class="line">rdd = sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], <span class="number">2</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(iterator)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"call f"</span></span><br><span class="line">    <span class="keyword">yield</span> sum(iterator)</span><br><span class="line">rdd.mapPartitions(f).collect() <span class="comment"># 调用2次f，分区求和</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">call f</span></span><br><span class="line"><span class="string">call f</span></span><br><span class="line"><span class="string">[6, 15]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<p><strong>mapPartitionsWithIndex(f)</strong></p>
<p>和<code>mapPartitions</code>一样，只是多了个partition的index。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="string">"yellow"</span>,<span class="string">"red"</span>,<span class="string">"blue"</span>,<span class="string">"cyan"</span>,<span class="string">"black"</span>], <span class="number">3</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(index, item)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"id-&#123;&#125;, &#123;&#125;"</span>.format(index, item)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(index, iterator)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'called f'</span></span><br><span class="line">    <span class="keyword">return</span> map(<span class="keyword">lambda</span> x: g(index, x), iterator)</span><br><span class="line">rdd.mapPartitionsWithIndex(f).collect()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">called f</span></span><br><span class="line"><span class="string">called f</span></span><br><span class="line"><span class="string">called f</span></span><br><span class="line"><span class="string">['id-0, yellow', 'id-1, red', 'id-1, blue', 'id-2, cyan', 'id-2, black']</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<p><strong>repartition(n)</strong></p>
<p>生成新的RDD，分区数目为n。会增加或者减少 RDD的并行度。会对分布式数据集进行<code>shuffle</code>操作，<strong>效率低</strong>。如果只是想减少分区数，则使用<code>coalesce</code>，不会进行shuffle操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>], <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sorted(rdd.glom().collect())</span><br><span class="line">[[<span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(rdd.repartition(<span class="number">2</span>).glom().collect())</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(rdd.repartition(<span class="number">10</span>).glom().collect())</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>
<p><strong>coalesce(n)</strong></p>
<p>合并，减少分区数，默认不执行shuffle操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="number">3</span>).glom().collect()</span><br><span class="line"><span class="comment"># [[1], [2, 3], [4, 5]]</span></span><br><span class="line">sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="number">3</span>).coalesce(<span class="number">1</span>).glom().collect()</span><br><span class="line"><span class="comment"># [[1, 2, 3, 4, 5]]</span></span><br></pre></td></tr></table></figure>
<p><strong>flatMapValues(f)</strong></p>
<p>打平values，[(&quot;k&quot;, [&quot;v1&quot;, &quot;v2&quot;])] -- [(&quot;k&quot;,&quot;v1&quot;), (&quot;k&quot;, &quot;v2&quot;)]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">"a"</span>, [<span class="string">"x"</span>, <span class="string">"y"</span>, <span class="string">"z"</span>]), (<span class="string">"b"</span>, [<span class="string">"p"</span>, <span class="string">"r"</span>])])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span> <span class="keyword">return</span> x</span><br><span class="line">x.flatMapValues(f).collect()</span><br><span class="line"><span class="comment"># [('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]</span></span><br></pre></td></tr></table></figure>
<p><strong>keys</strong></p>
<p><strong>values</strong></p>
<p><strong>sortByKey</strong></p>
<p>返回一个对键进行排序的RDD。会生成范围分区的RDD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">tmp = [(<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'b'</span>, <span class="number">2</span>), (<span class="string">'1'</span>, <span class="number">3</span>), (<span class="string">'d'</span>, <span class="number">4</span>), (<span class="string">'2'</span>, <span class="number">5</span>)]</span><br><span class="line">sc.parallelize(tmp).sortByKey().first()</span><br><span class="line"><span class="comment"># ('1', 3)</span></span><br><span class="line">sc.parallelize(tmp).sortByKey(<span class="keyword">True</span>, <span class="number">1</span>).collect()</span><br><span class="line"><span class="comment"># [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]</span></span><br><span class="line">sc.parallelize(tmp).sortByKey(<span class="keyword">True</span>, <span class="number">2</span>).collect()</span><br><span class="line"><span class="comment"># [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]</span></span><br><span class="line"></span><br><span class="line">tmp2 = [(<span class="string">'Mary'</span>, <span class="number">1</span>), (<span class="string">'had'</span>, <span class="number">2</span>), (<span class="string">'a'</span>, <span class="number">3</span>), (<span class="string">'little'</span>, <span class="number">4</span>), (<span class="string">'lamb'</span>, <span class="number">5</span>)]</span><br><span class="line">tmp2.extend([(<span class="string">'whose'</span>, <span class="number">6</span>), (<span class="string">'fleece'</span>, <span class="number">7</span>), (<span class="string">'was'</span>, <span class="number">8</span>), (<span class="string">'white'</span>, <span class="number">9</span>)])</span><br><span class="line">sc.parallelize(tmp2).sortByKey(<span class="keyword">True</span>, <span class="number">3</span>, keyfunc=<span class="keyword">lambda</span> k: k.lower()).collect()</span><br><span class="line"><span class="comment"># [('a', 3), ('fleece', 7), ('had', 2), ('lamb', 5),...('white', 9), ('whose', 6)]</span></span><br></pre></td></tr></table></figure>
<h4 id="两个pair-rdd转化">两个Pair RDD转化</h4>
<p><strong>substract</strong></p>
<p>留下在x中却不在y中的元素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">4</span>), (<span class="string">"b"</span>, <span class="number">5</span>), (<span class="string">"a"</span>, <span class="number">3</span>)])</span><br><span class="line">y = sc.parallelize([(<span class="string">"a"</span>, <span class="number">3</span>), (<span class="string">"c"</span>, <span class="keyword">None</span>)])</span><br><span class="line">sorted(x.subtract(y).collect())</span><br><span class="line"><span class="comment">#[('b', 4), ('b', 5)]</span></span><br></pre></td></tr></table></figure>
<p><strong>substractByKey</strong></p>
<p>删掉X中在Y中也存在的Key所包含的所有元素</p>
<p><strong>join</strong></p>
<p>内连接，从x中去和y中一个一个的匹配，(k, v1), (k, v2) -- (k, (v1, v2))</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">"a"</span>, <span class="number">1</span>), (<span class="string">"b"</span>, <span class="number">4</span>)])</span><br><span class="line">y = sc.parallelize([(<span class="string">"a"</span>, <span class="number">2</span>), (<span class="string">"a"</span>, <span class="number">3</span>)])</span><br><span class="line">sorted(x.join(y).collect())</span><br><span class="line"><span class="comment"># [('a', (1, 2)), ('a', (1, 3))]</span></span><br></pre></td></tr></table></figure>
<p><strong>leftOuterJoin</strong></p>
<p>左边RDD的键都有，右边没有的配None</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'b'</span>, <span class="number">4</span>)])</span><br><span class="line">y = sc.parallelize([(<span class="string">'a'</span>, <span class="number">2</span>)])</span><br><span class="line">sorted(x.leftOuterJoin(y).collect())</span><br><span class="line"><span class="comment"># [('a', (1, 2)), ('b', (4, None))]</span></span><br></pre></td></tr></table></figure>
<p><strong>rightOuterJoin</strong></p>
<p>右边RDD的键都有，左边没有的配None</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'b'</span>, <span class="number">4</span>)])</span><br><span class="line">y = sc.parallelize([(<span class="string">'a'</span>, <span class="number">2</span>)])</span><br><span class="line">sorted(x.rightOuterJoin(y).collect())</span><br><span class="line"><span class="comment"># [('a', (1, 2))]</span></span><br><span class="line">sorted(y.rightOuterJoin(x).collect())</span><br><span class="line"><span class="comment"># [('a', (2, 1)), ('b', (None, 4))]</span></span><br></pre></td></tr></table></figure>
<p><strong>cogroup</strong></p>
<p>将两个RDD中拥有相同键的value分组到一起，即使两个RDD的V不一样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = sc.parallelize([(<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'b'</span>, <span class="number">4</span>)])</span><br><span class="line">y = sc.parallelize([(<span class="string">'a'</span>, <span class="number">2</span>)])</span><br><span class="line">x.cogroup(y).collect()</span><br><span class="line"><span class="comment"># 上面显示的是16进制</span></span><br><span class="line">[(x, tuple(map(list, y))) <span class="keyword">for</span> x, y <span class="keyword">in</span> sorted(x.cogroup(y).collect())]</span><br><span class="line"><span class="comment"># [('a', ([1], [2])), ('b', ([4], []))]</span></span><br></pre></td></tr></table></figure>
<h3 id="行动操作">行动操作</h3>
<p><strong>countByKey</strong></p>
<p>对每个键对应的元素分别计数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([(<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'b'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">1</span>)])</span><br><span class="line">rdd.countByKey().items() <span class="comment"># 转换成一个dict，再取所有元素</span></span><br><span class="line"><span class="comment"># [('a', 2), ('b', 1)]</span></span><br></pre></td></tr></table></figure>
<p><strong>collectAsMap</strong></p>
<p>返回一个map</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = sc.parallelize([(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">4</span>)]).collectAsMap()</span><br><span class="line">m[<span class="number">1</span>] - <span class="number">2</span> <span class="comment"># 当做map操作即可</span></span><br><span class="line">m[<span class="number">3</span>] - <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p><strong>lookup(key)</strong></p>
<p>返回键的RDD中的值列表。如果RDD具有已知的分区器，则通过仅搜索key映射到的分区来高效地完成该操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">l = range(<span class="number">1000</span>) <span class="comment"># 1,2,3,...,1000</span></span><br><span class="line">rdd = sc.parallelize(zip(l, l), <span class="number">10</span>) <span class="comment"># 键和值一样，10个数据分片，10个并行度，10个task</span></span><br><span class="line">rdd.lookup(<span class="number">42</span>) <span class="comment"># slow</span></span><br><span class="line"><span class="comment"># [42]</span></span><br><span class="line">sorted_rdd = rdd.sortByKey()</span><br><span class="line">sorted_rdd.lookup(<span class="number">42</span>) <span class="comment"># fast</span></span><br><span class="line"><span class="comment"># [42]</span></span><br><span class="line">rdd = sc.parallelize([(<span class="string">'a'</span>, <span class="string">'a1'</span>), (<span class="string">'a'</span>, <span class="string">'a2'</span>), (<span class="string">'b'</span>, <span class="string">'b1'</span>)])</span><br><span class="line">rdd.lookup(<span class="string">'a'</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 'a1'</span></span><br></pre></td></tr></table></figure>
<h3 id="聚合操作">聚合操作</h3>
<p>当数据是键值对组织的时候，<strong>聚合具有相同键的元素</strong>是很常见的操作。基础RDD有<code>fold()</code>, <code>combine()</code>, <code>reduce()</code>，Pair RDD有<code>combineByKey()</code><strong>最常用</strong>,<code>reduceByKey()</code>, <code>foldByKey()</code>等。</p>
<p><strong>计算均值</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 方法一：mapValues和reduceByKey</span></span><br><span class="line">rdd = sc.parallelize([(<span class="string">'a'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">3</span>), (<span class="string">'b'</span>, <span class="number">4</span>)])</span><br><span class="line">maprdd = rdd.mapValues(<span class="keyword">lambda</span> x : (x, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># [('a', (1, 1)), ('a', (3, 1)), ('b', (4, 1))]</span></span><br><span class="line">reducerdd = maprdd.reduceByKey(<span class="keyword">lambda</span> x, y: (x[<span class="number">0</span>] + y[<span class="number">0</span>], x[<span class="number">1</span>] + y[<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># [('a', (4, 2)), ('b', (4, 1))]</span></span><br><span class="line">reducerdd.mapValues(<span class="keyword">lambda</span> x : x[<span class="number">0</span>]/x[<span class="number">1</span>]).collect()</span><br><span class="line"><span class="comment"># [('a', 2), ('b', 4)] </span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 方法二 combineByKey 最常用的</span></span><br><span class="line">nums = sc.parallelize([(<span class="string">'c'</span>, <span class="number">90</span>), (<span class="string">'m'</span>, <span class="number">95</span>), (<span class="string">'c'</span>, <span class="number">80</span>)])</span><br><span class="line">sum_count = nums.combineByKey(</span><br><span class="line">	<span class="keyword">lambda</span> x: (x, <span class="number">1</span>),</span><br><span class="line">    <span class="keyword">lambda</span> acc, x: (acc[<span class="number">0</span>] + x, acc[<span class="number">1</span>] + <span class="number">1</span>),</span><br><span class="line">    <span class="keyword">lambda</span> acc1, acc2: (acc1[<span class="number">0</span>] + acc2[<span class="number">0</span>], acc1[<span class="number">1</span>] + acc2[<span class="number">1</span>])</span><br><span class="line">)</span><br><span class="line"><span class="comment"># [('c', (170, 2)), ('m', (95, 1))]</span></span><br><span class="line">avg_map = sum_count.mapValues(<span class="keyword">lambda</span> (sum, count): sum/count).collectAsMap()</span><br><span class="line"><span class="comment"># &#123;'c': 85, 'm': 95&#125;</span></span><br><span class="line">avg_map = sum_count.map(<span class="keyword">lambda</span> key, s_c: (key, s_c[<span class="number">0</span>]/s_c[<span class="number">1</span>])).collectAsMap()</span><br></pre></td></tr></table></figure>
<p><strong>统计单词计数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.textFile(<span class="string">'README.md'</span>)</span><br><span class="line">words = rdd.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">' '</span>))</span><br><span class="line"><span class="comment"># 568个</span></span><br><span class="line">result = words.map(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> x, y: x+y)</span><br><span class="line"><span class="comment"># 289</span></span><br><span class="line">result.top(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># [('your', 1), ('you', 4)]</span></span><br></pre></td></tr></table></figure>
<h3 id="数据分区">数据分区</h3>
<p><strong>分区说明</strong></p>
<p>在分布式程序中，通信的代价是很大的。因此控制数据分布以获得<strong>最少的网络传输</strong>可以极大地提升整体性能。Spark程序通过<strong>控制RDD分区方式来减少通信开销</strong>。使用<code>partitionBy</code>进行分区</p>
<ul>
<li>不需分区：给定RDD只需要被扫描一次</li>
<li>需要分区：数据集在<strong>多次基于键的操作</strong>中使用，比如连接操作。<code>partitionBy</code>是<strong>转化操作</strong>，生成新的RDD，为了多次计算，一般要进行持久化<code>persist</code></li>
</ul>
<p>Spark中所有的键值对RDD都可以进行分区。系统会根据一个针对键的函数对元素进行分组。Spark不能显示控制具体每个键落在哪一个工作节点上，但是Spark可以确保同一组的键出现在同一个节点上。</p>
<ul>
<li>Hash分区：将一个RDD分成了100个分区，hashcode(key)%100 相同的，会在同一个节点上面</li>
<li>范围分区：将key在同一个范围区间内的记录放在同一个节点上</li>
</ul>
<p>一个简单的例子，内存中有一张很大的用户信息表 -- 即(UserId, UserInfo)组成的RDD，UserInfo包含用户订阅了的所有Topics。还有一张(UserId, LinkInfo)存放着过去5分钟用户浏览的Topic。现在要找出用户浏览了但是没有订阅的Topic数量。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(...)</span><br><span class="line"><span class="keyword">val</span> userData = sc.sequenceFile[<span class="type">UserId</span>, <span class="type">UserInfo</span>](<span class="string">"hdfs://..."</span>).persist()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">processNewLog</span></span>(logFileName: <span class="type">String</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> events = sc.sequenceFile[<span class="type">UserId</span>, <span class="type">LinkInfo</span>](logFileName)</span><br><span class="line">  <span class="keyword">val</span> joined = userData.join(events)	<span class="comment">// (UserId, (UserInfo, LinkInfo))</span></span><br><span class="line">  <span class="keyword">val</span> offTopicVisits = joined.filter&#123;</span><br><span class="line">    <span class="keyword">case</span> (<span class="type">UserId</span>, (<span class="type">UserInfo</span>, <span class="type">LinkInfo</span>)) =&gt;</span><br><span class="line">    	!<span class="type">UserInfo</span>.topics.contains(<span class="type">LinkInfo</span>.topic)</span><br><span class="line">  &#125;.count()</span><br><span class="line">  print (<span class="string">"浏览了且未订阅的数量："</span> + offTopicVisits)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码<strong>不够高效</strong>。因为每次调用<code>processNewLog</code>都会用<code>join</code>操作，但我们却不知道数据集是如何分区的。</p>
<blockquote>
<p><strong>连接操作</strong>，会将两个数据集的所有键的哈希值都求出来，将该哈希值相同的记录通过网络传到同一台机器上，然后在机器上对所有键相同的记录进行操作。</p>
</blockquote>
<p>因为userData比events要大的多并且基本不会变化，所以有很多浪费效率的事情：每次调用时都对userData表进行计算hash值计算和跨节点数据混洗。</p>
<p><strong>解决方案</strong>：在程序开始的时候，对userData表使用<code>partitionBy()</code>转换操作，将<strong>这张表转换为哈希分区</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> userData = sc.sequenceFile[<span class="type">UserId</span>, <span class="type">UserInfo</span>](<span class="string">"hdfs://..."</span>)</span><br><span class="line">					.partitionBy(<span class="keyword">new</span> <span class="type">HashPartioner</span>(<span class="number">100</span>))	<span class="comment">// 构造100个分区</span></span><br><span class="line">					.persist()								<span class="comment">// 持久化当前结果</span></span><br></pre></td></tr></table></figure>
<p>events是本地变量，并且只使用一次，所以为它指定分区方式没有什么用处。</p>
<p>userData使用了<code>partitionBy()</code>，Spark就知道该RDD是根据键的hash值来分区的。在<code>userData.join(events)</code>时，Spark<strong>只会对events进行数据混洗操作</strong>。将events中特定UserId的记录发送到userData的对应分区所在的那台机器上。需要网络传输的数据就大大减少了，速度也就显著提升了。</p>
<p><strong>分区相关的操作</strong></p>
<p>Spark的许多操作都有将数据根据跨节点进行混洗的过程。所有这些操作都会从数据分区中获益。类似<code>join</code>这样的二元操作，预先进行数据分区会导致其中至少一个RDD<code>不发生数据混洗</code>。</p>
<blockquote>
<p>获取好处的操作：<code>cogroup</code>, <code>groupWith</code>, <code>join</code>, <code>leftOuterJoin</code> , <code>rightOuterJoin</code>, <code>groupByKey</code>, <code>reduceByKey</code> , <code>combineByKey</code>, <code>lookup</code></p>
<p>为结果设好分区的操作：<code>cogroup</code>, <code>groupWith</code>, <code>join</code>, <code>leftOuterJoin</code> , <code>rightOuterJoin</code>, <code>groupByKey</code>, <code>reduceByKey</code> , <code>combineByKey</code>, <code>partitionBy</code>, <code>sort</code>, （<code>mapValues</code>, <code>flatMapValues</code>, <code>filter</code> 如果父RDD有分区方式的话）</p>
</blockquote>
<p>其他所有的操作的结果都不会存在特定的分区方式。对于二元操作，输出数据的分区方式取决于父RDD的分区方式。默认情况结果会采取hash分区。</p>
<p><strong>PageRank</strong></p>
<p>PageRank的python版本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">""" PageRank算法</span></span><br><span class="line"><span class="string">author = PuLiming</span></span><br><span class="line"><span class="string">运行: bin/spark-submit files/pagerank.py data/mllib/pagerank_data.txt 10</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_contribs</span><span class="params">(urls, rank)</span>:</span></span><br><span class="line">    <span class="string">""" 给urls计算</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        urls: 目标url相邻的urls集合</span></span><br><span class="line"><span class="string">        rank: 目标url的当前rank</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        url: 相邻urls中的一个url</span></span><br><span class="line"><span class="string">        rank: 当前url的新的rank</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    num_urls = len(urls)</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        <span class="keyword">yield</span> (url, rank / num_urls)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_url</span><span class="params">(url_line)</span>:</span></span><br><span class="line">    <span class="string">""" 把一行url切分开来</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        url_line: 一行url，如 1 2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        url, neighbor_url</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    parts = re.split(<span class="string">r'\s+'</span>, url_line) <span class="comment"># 正则</span></span><br><span class="line">    <span class="keyword">return</span> parts[<span class="number">0</span>], parts[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_pagerank</span><span class="params">(sc, url_data_file, iterations)</span>:</span></span><br><span class="line">    <span class="string">""" 计算各个page的排名</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        sc: SparkContext</span></span><br><span class="line"><span class="string">        url_data_file: 测试数据文件</span></span><br><span class="line"><span class="string">        iterations: 迭代次数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        status: 成功就返回0</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取url文件 ['1 2', '1 3', '2 1', '3 1'] </span></span><br><span class="line">    lines = sc.textFile(url_data_file).map(<span class="keyword">lambda</span> line: line.encode(<span class="string">'utf8'</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 建立Pair RDD (url, neighbor_urls) [(1,[2,3]), (2,[1]), (3, [1])]</span></span><br><span class="line">    links = lines.map(<span class="keyword">lambda</span> line : split_url(line)).distinct().groupByKey().mapValues(<span class="keyword">lambda</span> x: list(x)).cache()</span><br><span class="line">    <span class="comment"># 初始化所有url的rank为1 [(1, 1), (2, 1), (3, 1)]</span></span><br><span class="line">    ranks = lines.map(<span class="keyword">lambda</span> line : (line[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</span><br><span class="line">        <span class="comment"># (url, [(neighbor_urls), rank]) join neighbor_urls and rank </span></span><br><span class="line">        <span class="comment"># 把当前url的rank分别contribute到其他相邻的url (url, rank)</span></span><br><span class="line">        contribs = links.join(ranks).flatMap(</span><br><span class="line">            <span class="keyword">lambda</span> url_urls_rank: compute_contribs(url_urls_rank[<span class="number">1</span>][<span class="number">0</span>], url_urls_rank[<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 把url的所有rank加起来，再赋值新的</span></span><br><span class="line">        ranks = contribs.reduceByKey(add).mapValues(<span class="keyword">lambda</span> rank : rank * <span class="number">0.85</span> + <span class="number">0.15</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (link, rank) <span class="keyword">in</span> ranks.collect():</span><br><span class="line">        print(<span class="string">"%s has rank %s."</span> % (link, rank)) </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) != <span class="number">3</span>:</span><br><span class="line">        print(<span class="string">"Usage: python pagerank.py &lt;data.txt&gt; &lt;iterations&gt;"</span>, file = sys.stderr)</span><br><span class="line">        sys.exit(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据文件和迭代次数</span></span><br><span class="line">    url_data_file = sys.argv[<span class="number">1</span>]</span><br><span class="line">    iterations = int(sys.argv[<span class="number">2</span>])</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 配置 SparkContext</span></span><br><span class="line">    conf = SparkConf().setAppName(<span class="string">'PythonPageRank'</span>)</span><br><span class="line">    conf.setMaster(<span class="string">'local'</span>)</span><br><span class="line">    sc = SparkContext(conf=conf)</span><br><span class="line"></span><br><span class="line">    ret = compute_pagerank(sc, url_data_file, iterations)</span><br><span class="line">    sys.exit(ret)</span><br></pre></td></tr></table></figure>
<p>PageRank的scala版本</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(...)</span><br><span class="line"><span class="keyword">val</span> links = sc.objectFile[(<span class="type">String</span>, <span class="type">Seq</span>[<span class="type">String</span>])](<span class="string">"links"</span>)</span><br><span class="line">				.partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">100</span>))</span><br><span class="line">				.persist()</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> ranks = links.mapValues(_ =&gt; <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 迭代10次</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">0</span> until <span class="number">10</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> contributions = links.join(ranks).flatMap &#123;</span><br><span class="line">    <span class="keyword">case</span> (pageId, (links, rank)) =&gt;</span><br><span class="line">    	links.map(dest =&gt; (dest, rank / links.size))</span><br><span class="line">  &#125;</span><br><span class="line">  ranks = contributions.reduceByKey(_ + _).mapValues(<span class="number">0.15</span> + <span class="number">0.85</span>* _)</span><br><span class="line">&#125;</span><br><span class="line">ranks.saveAsTextFile(<span class="string">"ranks"</span>)</span><br></pre></td></tr></table></figure>
<p>当前scala版本的PageRank算法的优点：</p>
<ul>
<li>links每次都会和ranks发生连接操作，所以一开始就对它进行分区<code>partitionBy</code>，就不会通过网络进行数据混洗了，节约了相当可观的网络通信开销</li>
<li>对links进行<code>persist</code>，留在内存中，每次迭代使用</li>
<li>第一次创建ranks，使用<code>mapValues</code>保留了父RDD的分区方式，第一次连接开销就会很小</li>
<li><code>reduceByKey</code>后已经是分区了，再使用<code>mapValues</code>分区方式，再次和links进行<code>join</code>就会更加<strong>高效</strong></li>
</ul>
<p>所以对分区后的RDD尽量使用<code>mapValues</code>保留父分区方式，而不要用<code>map</code>丢失分区方式。</p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2017-09-22T03:26:56.000Z" itemprop="dateUpdated">2017-09-22 11:26:56</time>
</span><br>


        
        <br>原始链接：<a href="/2017/03/13/Spark-PairRDD/" target="_blank" rel="external">http://plmsmile.github.io/2017/03/13/Spark-PairRDD/</a>
        
    </div>
    <footer>
        <a href="http://plmsmile.github.io">
            <img src="/img/avatar.jpg" alt="PLM">
            PLM
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PairRDD/">PairRDD</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/&title=《Spark的键值对RDD》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/&title=《Spark的键值对RDD》 — PLM's Notes&source=NLP，DL，ML，Leetcode，Java/C++你学了吗？" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Spark的键值对RDD》 — PLM's Notes&url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2017/03/13/博客搭建过程及问题/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">博客搭建过程及问题</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2017/03/13/Spark-BaseRDD/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Spark的基础RDD</h4>
      </a>
    </div>
  
</nav>



    














</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.png" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.png" data-alipay="/img/alipay.png">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <!-- <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div> -->
    <div class="bottom">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
          <span>

          <!-- PLM  -->
          PLM's Notes &nbsp;
          &copy;
          &nbsp;
          2016 - 2018

          </span>
            <!-- <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span> -->
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/&title=《Spark的键值对RDD》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/&title=《Spark的键值对RDD》 — PLM's Notes&source=NLP，DL，ML，Leetcode，Java/C++你学了吗？" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Spark的键值对RDD》 — PLM's Notes&url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2017/03/13/Spark-PairRDD/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACL0lEQVR42u3aQU7EMBAEQP7/aZAQB6Rll+6xQYpTOa1CSFw5jCY9fnuLj/fP4/HM9/OPvx+veX3n5PqlAwMD47KM95dH/rBn1+dPSV7HUyoGBsYNGG0pTBad3D9/fb+sGQMDA2OB2raMGBgYGLsKbt26lVQMDAyMWYuWL65tBJPnbvsWx8DAuCCjHQz85+8/nG9gYGBchDErgvlQM4/7Z+v5+l8MDIyjGUms/7qyzbZfJNUyuWe0HwQDA+PijFkRbPu05Mq2iD8ttRgYGMcx8rKbB/T55ol6iUm0h4GBcRxjVmTzJi/v3/KXiIGBcU9GUl6TD8uVDRYrH70YGBh3YMyirvyvSZu4xMbAwLgBo23I2tHjLJgrYjgMDIyjGXmZSxbXbr9YH2RiYGDcgdFG9vlyo10eC2UXAwMDY++i24/YuohjYGDchtEeebOYt5vDjRoYGBhHM14XuDw4m8Vke+M5DAyMsxltoDYbVc7KbtE4YmBg3IbRltp2C8X6wODpUzAwMA5l5AOAlWCuXfqGDRYYGBjHMdoy10b/K+yoecXAwDia0UZseRPZDj43DCQwMDAOZewdJc4KcfsJ/cNKMDAwjma0Za4N3VZKavIZjIGBcR/GrMjWoVj8RouZRr6PAwMD4whGPnTM47OVIt7GcxgYGBhJa7jrzHDTGAYGBsZy0J8sJY/Y6nksBgbGEYw8rJ8FcLMWc7jHDQMD4zjGSlg/axZn4d2GwQMGBsb1GB+u7Kh2Ai879QAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.0"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.0" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
