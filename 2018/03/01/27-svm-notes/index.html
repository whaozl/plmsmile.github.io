<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    <title>SVM笔记 | PLM&#39;s Notes | 好好学习，天天笔记</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="SVM,机器学习,拉格朗日对偶性,对偶问题">
    <meta name="description" content="Support Vector Machine简单笔记。 特征空间上的间隔最大的线性分类器。学习策略是间隔最大化，转化为一个凸二次规划问题的求解。   SVM概览 线性分类器 逻辑回归的图像和公式如下，预测的分类为1的概率。  \[ h_\theta(x) = g(\theta^Tx), \quad g(z">
<meta name="keywords" content="SVM,机器学习,拉格朗日对偶性,对偶问题">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM笔记">
<meta property="og:url" content="http://plmsmile.github.io/2018/03/01/27-svm-notes/index.html">
<meta property="og:site_name" content="PLM&#39;s Notes">
<meta property="og:description" content="Support Vector Machine简单笔记。 特征空间上的间隔最大的线性分类器。学习策略是间隔最大化，转化为一个凸二次规划问题的求解。   SVM概览 线性分类器 逻辑回归的图像和公式如下，预测的分类为1的概率。  \[ h_\theta(x) = g(\theta^Tx), \quad g(z) = \frac{1}{1+e^{-z}}, \quad g(z) =">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://otafnwsmg.bkt.clouddn.com/image/ml/lr/sigmoid%E5%87%BD%E6%95%B0.png">
<meta property="og:image" content="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/linear-desicion">
<meta property="og:image" content="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/linear-desicion2">
<meta property="og:image" content="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/margin-1">
<meta property="og:image" content="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/margin-2">
<meta property="og:updated_time" content="2018-03-02T12:02:23.887Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SVM笔记">
<meta name="twitter:description" content="Support Vector Machine简单笔记。 特征空间上的间隔最大的线性分类器。学习策略是间隔最大化，转化为一个凸二次规划问题的求解。   SVM概览 线性分类器 逻辑回归的图像和公式如下，预测的分类为1的概率。  \[ h_\theta(x) = g(\theta^Tx), \quad g(z) = \frac{1}{1+e^{-z}}, \quad g(z) =">
<meta name="twitter:image" content="http://otafnwsmg.bkt.clouddn.com/image/ml/lr/sigmoid%E5%87%BD%E6%95%B0.png">
    
        <link rel="alternate" type="application/atom+xml" title="PLM&#39;s Notes" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.0">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="https://plmsmile.github.io/about" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">PLM</h5>
          <a href="mailto:plmsmile@126.com" title="plmsmile@126.com" class="mail">plmsmile@126.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                类别
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about"  >
                <i class="icon icon-lg icon-user"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/plmsmile" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">SVM笔记</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">SVM笔记</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-03-01T12:42:20.000Z" itemprop="datePublished" class="page-time">
  2018-03-01
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#svm概览"><span class="post-toc-number">1.</span> <span class="post-toc-text">SVM概览</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#线性分类器"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">线性分类器</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#函数间隔与几何间隔"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">函数间隔与几何间隔</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#最大间隔分类器"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">最大间隔分类器</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#svm第二层"><span class="post-toc-number">2.</span> <span class="post-toc-text">SVM第二层</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#拉格朗日对偶性"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">拉格朗日对偶性</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#原始问题到对偶问题"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">原始问题到对偶问题</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#求解对偶问题"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">求解对偶问题</span></a></li></ol></li></ol>
        </nav>
    </aside>
    
<article id="post-27-svm-notes"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">SVM笔记</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-03-01 20:42:20" datetime="2018-03-01T12:42:20.000Z"  itemprop="datePublished">2018-03-01</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <blockquote>
<p>Support Vector Machine简单笔记。 特征空间上的间隔最大的线性分类器。学习策略是间隔最大化，转化为一个凸二次规划问题的求解。</p>
</blockquote>
<p><img src="" style="display:block; margin:auto" width="60%"></p>
<h1 id="svm概览">SVM概览</h1>
<h2 id="线性分类器">线性分类器</h2>
<p><a href="https://plmsmile.github.io/2017/08/20/ml-ng-notes/#逻辑回归">逻辑回归</a>的图像和公式如下，预测的分类为1的概率。</p>
<p><img src="http://otafnwsmg.bkt.clouddn.com/image/ml/lr/sigmoid%E5%87%BD%E6%95%B0.png" style="display:block; margin:auto" width="50%"> <span class="math display">\[
h_\theta(x) = g(\theta^Tx), \quad g(z) = \frac{1}{1+e^{-z}},
\quad
g(z) = \begin{cases}
1, &amp; z\ge 0 \\
-1, &amp; z &lt; 0 \\
\end{cases}
\]</span></p>
<p><span class="math display">\[
y = \begin{cases}    1, \;  &amp; h_\theta(x) \ge 0.5, \;即\; \theta^Tx \ge 0\\    0, \; &amp; h_\theta(x) &lt; 0.5,  \; 即 \; \theta^Tx &lt; 0 \\\end{cases}
\]</span></p>
<p>其中<span class="math inline">\(\theta^Tx=w^Tx+b=0\)</span> 是一个<code>超平面</code>。 用<code>分类函数</code>表示<span class="math inline">\(f(x)=w^Tx+b\)</span> 。 <span class="math inline">\(w\)</span>是这个超平面的<strong>法向量</strong>。</p>
<p><img src="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/linear-desicion" style="display:block; margin:auto" width="35%"></p>
<p><img src="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/linear-desicion2" style="display:block; margin:auto" width="60%"></p>
<p>即对于任意一个x，有如下<strong>预测类别</strong>： <span class="math display">\[
\hat y=\begin{cases}
1, &amp; f(x) &gt; 0\\
-1, &amp; f(x) &lt; 0 \\
\end{cases}
\]</span></p>
<h2 id="函数间隔与几何间隔">函数间隔与几何间隔</h2>
<p><strong>函数间隔</strong></p>
<p>超平面<span class="math inline">\(w^Tx+b=0\)</span>确定后， <span class="math inline">\(\vert w\cdot x+b\vert\)</span>表示点x到平面的<code>距离</code>，表示分类<strong>可靠性</strong>。<strong>距离越远，分类越可信</strong>。y与<span class="math inline">\(w\cdot x+b\)</span>的符号的一致性表示分类的<strong>正确性</strong>。</p>
<p>超平面<span class="math inline">\((w,b)\)</span>关于样本点<span class="math inline">\((x_i, y_i)\)</span>的<strong>函数间隔<span class="math inline">\(\hat \gamma_i\)</span></strong>如下： <span class="math display">\[
\hat \gamma_i = y_i (w \cdot x_i + b)
\]</span> 超平面关于所有样本点的函数间隔<span class="math inline">\(\hat \gamma\)</span> ： <span class="math display">\[
\hat \gamma = \min \hat \gamma_i
\]</span> 函数间隔的<strong>问题</strong>：w和b成比例改变，超平面未变，但函数间隔已变。</p>
<p><strong>几何间隔</strong></p>
<p>对函数间隔除以法向量的<a href="https://plmsmile.github.io/2017/11/26/cs224n-notes3-neural-networks-2/#范数">二范数</a>，则得到超平面与点<span class="math inline">\((x_i,y_i)\)</span>的<strong>几何间隔<span class="math inline">\(\gamma_i\)</span></strong> ： <span class="math display">\[
\gamma_i = \frac{\hat \gamma_i}{\|w\|} = \frac{y_i(w\cdot x_i + b)}{\|w\|}
\]</span> 超平面关于所有样本点的几何间隔： <span class="math display">\[
\gamma = \min \gamma_i
\]</span> <code>几何间隔</code>才是直观上<strong>点到超平面的距离</strong>。</p>
<h2 id="最大间隔分类器">最大间隔分类器</h2>
<p>分类时，超平面离数据点的<strong>间隔越大</strong>，<strong>分类的确信度也越大</strong>。 所以要<strong>最大化这个几何间隔</strong>，目标函数如下： <span class="math display">\[
L = \max_\limits{w, b} \gamma, \quad s.t,\quad \gamma_i \ge \gamma
\]</span> <img src="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/margin-1" style="display:block; margin:auto" width="40%"></p>
<p>用函数间隔<span class="math inline">\(\hat \gamma\)</span>描写为： <span class="math display">\[
L = \max_\limits{w, b} \frac{\hat \gamma}{\|w\|}, \quad s.t, \quad \hat \gamma_i \ge \hat \gamma, \; \text{ 其中 }\hat \gamma_i = y_i(w \cdot x_i + b)
\]</span> <strong>函数间隔</strong><span class="math inline">\(\hat \gamma\)</span>的取值并<strong>不会影响最优化问题的解</strong>。 <span class="math inline">\(\lambda w, \lambda b \to \lambda \hat \gamma\)</span></p>
<p><strong>目标函数</strong></p>
<p><strong>取函数间隔为1</strong>，<span class="math inline">\(\hat \gamma = 1\)</span>， 则有<strong>目标函数</strong>： <span class="math display">\[
L = \max_\limits{w,b} \frac{1}{\|w\|}, \quad s.t, \quad y_i(wx_i+b) \ge 1
\]</span> <img src="http://otafnwsmg.bkt.clouddn.com/image/ml/svm/margin-2" style="display:block; margin:auto" width="70%"></p>
<p>支持向量是虚线边界上的点，则有： <span class="math display">\[
\begin{cases}
y_i(wx_i+b)=1, &amp; 支持向量 \\
y_i(wx_i+b) &gt;1, &amp; 其他点 \\
\end{cases}
\]</span></p>
<h1 id="svm第二层">SVM第二层</h1>
<h2 id="拉格朗日对偶性">拉格朗日对偶性</h2>
<p><strong>1 原始问题</strong></p>
<p><span class="math inline">\(f(x), c_i(x), h_j(x)\)</span>都连续可微。</p>
<p>最优化： <span class="math display">\[
\min_\limits{x\in R} f(x)
\]</span> 有很多个约束条件（不等式约束和等式约束）： <span class="math display">\[
c_i(x) \le 0 ,\quad h_j(x) = 0
\]</span> <strong>求解原始问题</strong></p>
<p>将约束问题无约束化。</p>
<p>引入<strong>拉格朗日函数</strong>，其中<span class="math inline">\(\alpha_i (\ge 0)\)</span>和<span class="math inline">\(\beta_j\)</span>是<strong>拉格朗日乘子</strong><br>
<span class="math display">\[
L(x, \alpha, \beta) = f(x) + \sum\alpha_ic_i(x) + \sum \beta_j h_j(x)
\]</span> 定义关于<span class="math inline">\(x\)</span>的函数<strong><span class="math inline">\(\theta_p(x)\)</span></strong>： <span class="math display">\[
\theta_p(x) = \max_\limits{\alpha,\beta:\alpha_i\ge0} L(x, \alpha, \beta) 
\]</span></p>
<p><span class="math display">\[
\theta_p(x) = \begin{cases}
f(x), &amp;x满足约束 \\
+\infty, &amp; 其他 \\
\end{cases}
\]</span></p>
<p><span class="math inline">\(f(x)\)</span>求最小，则对<span class="math inline">\(\theta_p(x)\)</span>求最小。</p>
<p>原始问题： <strong>先固定x，优化出参数<span class="math inline">\(\alpha, \beta\)</span>，再优化x</strong>。 <span class="math display">\[
\min_\limits{x} \; \theta_p(x) =  \min_\limits{x} \max_\limits{\alpha, \beta:\alpha_i\ge0} L(x, \alpha, \beta)
\]</span> 所以<strong>原始最优化问题</strong> 变为 拉格朗日函数的<strong>极小极大问题</strong>。</p>
<p>定义原始问题的最优解<span class="math inline">\(p^*\)</span> ： <span class="math display">\[
p^* = \min_\limits{x} \theta_p(x)
\]</span> <strong>2 对偶问题</strong></p>
<p>定义关于<span class="math inline">\(\alpha, \beta\)</span>的函数<span class="math inline">\(\theta_d(\alpha, \beta)\)</span> <span class="math display">\[
\theta_d(\alpha, \beta) = \min_x L(x, \alpha, \beta)
\]</span> 对偶问题：<strong>先固定参数<span class="math inline">\(\alpha, \beta\)</span> ，优化出x，再优化出参数</strong>。 <strong>先优化x</strong>。 <span class="math display">\[
\max_\limits{\alpha, \beta:\alpha_i\ge0} \theta_d(\alpha, \beta) = \max_\limits{\alpha, \beta:\alpha_i\ge0} \min_x L(x, \alpha, \beta)
\]</span> 原始问题： <strong>先固定x，优化出参数<span class="math inline">\(\alpha, \beta\)</span>，再优化x</strong>。先优化参数。 <span class="math display">\[
\min_\limits{x} \; \theta_p(x) =  \min_\limits{x} \max_\limits{\alpha, \beta:\alpha_i\ge0} L(x, \alpha, \beta)
\]</span> 定义对偶问题的最优值： <span class="math display">\[
d^* = \max_\limits{\alpha, \beta:\alpha_i\ge0} \theta_d(\alpha, \beta)
\]</span></p>
<p><strong>3 原始问题与对偶问题的关系</strong></p>
<p>因为： <span class="math display">\[
\theta_d(\alpha, \beta) = \min_x L(x, \alpha, \beta) \le \max_\limits{\alpha,\beta:\alpha_i\ge0} L(x, \alpha, \beta) = \theta_p(x)
\]</span> 定理1：如果原始问题与对偶问题均有最优值，则有：<span class="math inline">\(d^* \le p^*\)</span> <span class="math display">\[
d^* = \max_\limits{\alpha, \beta:\alpha_i\ge0} \min_x L(x, \alpha, \beta)
  \le \min_\limits{x} \max_\limits{\alpha, \beta:\alpha_i\ge0} L(x, \alpha, \beta) = p^*
\]</span> 推论1：如果<span class="math inline">\(d^* = p^*\)</span>， 那么<span class="math inline">\(x^*, \alpha^*, \beta^*\)</span>分别是原始问题和对偶问题的最优解。</p>
<p>通过对偶问题，来解决原始问题。</p>
<p><strong>4 KKT条件</strong></p>
<p>满足什么条件，才能使<span class="math inline">\(d^* = p^*\)</span>呢 ？</p>
<p>首先满足下面的大条件：</p>
<blockquote>
<p>假设<span class="math inline">\(f(x)\)</span>和<span class="math inline">\(c_i(x)\)</span>都是<a href="https://plmsmile.github.io/2017/08/13/em/#em算法">凸函数</a>， <span class="math inline">\(h_j(x)\)</span>是仿射函数；假设不等式约束<span class="math inline">\(c_i(x)\)</span>是严格可行的。</p>
</blockquote>
<p>定理2：则存在解，<span class="math inline">\(x^*\)</span>是原始问题的最优解，<span class="math inline">\(\alpha^*, \beta^*\)</span>是对偶问题的最优解。 并且： <span class="math display">\[
d^* = p^* = L(x^*, \alpha^*, \beta^*)
\]</span> KKT条件：则<span class="math inline">\(x^*\)</span>是原始问题、<span class="math inline">\(\alpha^*, \beta^*\)</span>是对偶问题的最优解的<code>充分必要条件</code>是<strong><span class="math inline">\(x^*, \alpha^*, \beta^*\)</span>满足下面的KKT条件</strong>： <span class="math display">\[
\begin{align}
&amp; 偏导为0条件\\
&amp; \nabla_x L(x^*, \alpha^*, \beta^*)  = 0 \\
&amp; \nabla_\alpha L(x^*, \alpha^*, \beta^*)  = 0 \\
&amp; \nabla_\beta L(x^*, \alpha^*, \beta^*)  = 0 \\
&amp; 约束条件 \\
&amp; c_i(x^*) \le 0 \\
&amp; h_j(x^*) = 0 \\
&amp; \alpha_i^* \ge 0 \\
&amp; \rm{KKT}对偶互补条件 \\
&amp; \alpha_i^* c_i(x^*) = 0 \\
\end{align}
\]</span> 由KKT对偶互补条件可知，若<span class="math inline">\(\alpha_i^* &gt;0\)</span>， 则<span class="math inline">\(c_i(x^*)=0\)</span> 。SVM推导会用到。</p>
<h2 id="原始问题到对偶问题">原始问题到对偶问题</h2>
<p>先前的目标函数： <span class="math display">\[
J = \max_\limits{w,b} \frac{1}{\|w\|}, \quad s.t, \quad y_i(wx_i+b) \ge 1
\]</span> 最大变为最小，则有<code>原始问题</code>如下。目标函数是二次的，约束条件是线性的。所以是个<code>凸二次规划问题</code>。 <span class="math display">\[
J = \min_{w,b} \frac{1}{2} \|w\|^2, \quad s.t, \quad y_i(wx_i+b) \ge 1
\]</span> 构造<strong>拉格朗日函数</strong> ： <span class="math display">\[
L(w, b, \lambda) =\frac{1}{2} \|w\|^2 - \sum_{i=1}^n \lambda_i \left(y_i(wx_i+b) - 1\right)
\]</span> 原始问题 <span class="math display">\[
\theta_p(w,b) = \max_{\lambda_i \ge 0} L(w, b, \lambda)
\]</span></p>
<p><span class="math display">\[
p^* = \min_{w, b} \theta_p(w, b) =  \min_{w, b} \max_{\lambda_i \ge 0} L(w, b, \lambda)
\]</span></p>
<p>对偶问题 <span class="math display">\[
\theta_d(\lambda) = \min_{w,b} L(w, b, \lambda)
\]</span></p>
<p><span class="math display">\[
d^* = \max_{\lambda_i \ge 0} \theta_d(\lambda) =  \max_{\lambda_i \ge 0} \min_{w,b} L(w, b, \lambda)
\]</span></p>
<p>我们知道<span class="math inline">\(d^* \le p^*\)</span>， 有时相等。原始问题转化为对偶问题的原因：<strong>近似解</strong>，<strong>好求解</strong>。</p>
<h2 id="求解对偶问题">求解对偶问题</h2>
<p>主要是三个步骤：</p>
<ul>
<li>固定参数<span class="math inline">\(\lambda\)</span>， 求 极小化<span class="math inline">\(\min_{w,b} L(w, b, \lambda)\)</span>的w和b<br>
</li>
<li>带入w和b，对<span class="math inline">\(L\)</span>求参数<span class="math inline">\(\lambda\)</span> 的极大化</li>
<li>利用SMO算法求解对偶问题中的拉格朗日乘子</li>
</ul>
<strong>1 对wb的极小化</strong> $$
<span class="math display">\[\begin{align}
&amp; \frac{\partial L}{\partial w} = 0  \to \\
&amp; \frac{\partial L}{\partial b} = 0 \to \\

\end{align}\]</span>
<p>$$</p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2018-03-02T12:02:23.887Z" itemprop="dateUpdated">2018-03-02 20:02:23</time>
</span><br>


        
        <br>原始链接：<a href="/2018/03/01/27-svm-notes/" target="_blank" rel="external">http://plmsmile.github.io/2018/03/01/27-svm-notes/</a>
        
    </div>
    <footer>
        <a href="http://plmsmile.github.io">
            <img src="/img/avatar.jpg" alt="PLM">
            PLM
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SVM/">SVM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/对偶问题/">对偶问题</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/拉格朗日对偶性/">拉格朗日对偶性</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2018/03/01/27-svm-notes/&title=《SVM笔记》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2018/03/01/27-svm-notes/&title=《SVM笔记》 — PLM's Notes&source=NLP，DL，ML，Leetcode，Java/C++你学了吗？" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2018/03/01/27-svm-notes/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《SVM笔记》 — PLM's Notes&url=http://plmsmile.github.io/2018/03/01/27-svm-notes/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2018/03/01/27-svm-notes/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2018/03/02/aim2offer4/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">Aim2offer4(51-64)</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/02/10/ide-envs/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">ide-envs</h4>
      </a>
    </div>
  
</nav>



    














</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.png" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.png" data-alipay="/img/alipay.png">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>PLM &copy; 2016 - 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2018/03/01/27-svm-notes/&title=《SVM笔记》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2018/03/01/27-svm-notes/&title=《SVM笔记》 — PLM's Notes&source=NLP，DL，ML，Leetcode，Java/C++你学了吗？" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2018/03/01/27-svm-notes/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《SVM笔记》 — PLM's Notes&url=http://plmsmile.github.io/2018/03/01/27-svm-notes/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2018/03/01/27-svm-notes/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACKklEQVR42u3aS27DMAxF0ex/0+60QGDnPlIeiLoaFYkj+3jA8qPPB6/rZv3/9u56sif/VWvJkCFjW8b1uO6u+d6B3+X7V/y+t1QZMmQcwLi7MX9Q8isSmsl9ZciQIeN5uzSl4wmlDBkyZKwNuCRE8lSPBF8ZMmTI4A215/SOtNjSoLy4FpchQ8aGjE5p+vbfr8w3ZMiQsRXjChcPmrVPakuGDBmzGZ0BJG/9L2ilkeeRIUPGAYz06EOaoaXHL9LXJ0OGjBMYnSQvbfR3ksjg/4YMGTJGMFbd+DksplemaaIMGTJmM/gwoJYIpg9NBqLxIFOGDBmbM9KksHP0Ib0yaNLJkCFjNKO2Xb+V1t85zn9lyJCxLYOncSR1Sw9ncMaPT2TIkDGawaMyb9OT15EG1jjFlCFDxiBGreH1RnHbGg/IkCHjeEYaiGtBlofpHxmuDBkyhjLIqDJt3KclcZrJypAh40zGKlLnWAYPwTJkyDiHkZayaes/HVXWUlUZMmScw+gcoeBhmh+/4Ec0ZMiQcSaDPDQJmrVjXnxnNM2QIUPGIEZK4kGTN+k+YKEiVoYMGYMYV7jSYWSnhcdLXBkyZMxm8NXZetX1afEsQ4aMSYxOacqLzzQEx69MhgwZBzD6Df1a+lgrYmXIkCGjll3WBpm19pwMGTJk8IMOtSYd2ZO35GTIkHEOo/MQnW/RlHVtu02GDBkbMlqlYzi85E235/2LQ00ZMmTsx/gDJvJBzw1eFQkAAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.0"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.0" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
